# **The Architecture, Evaluation, and Integration of Large Language Models as Dungeon Masters in Tabletop Role-Playing Games**

## **The Paradigm Shift in Interactive Narratives and Agentic Simulation**

The integration of Large Language Models (LLMs) into tabletop role-playing games (TTRPGs), specifically serving as artificial Dungeon Masters (DMs) or Game Masters (GMs), represents a critical intersection of natural language processing, stochastic narrative generation, and deterministic rule execution. The development of AI-driven DMs is not merely an endeavor in entertainment technology; rather, it has emerged as a premier testing ground for evaluating the long-term decision-making, strategic reasoning, and multi-agent coordination capabilities of advanced AI models.1 TTRPGs like Dungeons & Dragons (D\&D) require a synthesis of probabilistic outcomes, incomplete information, and rigid mechanical constraints, making them an unparalleled sandbox for autonomous agent research.3

The current state of AI DMs demonstrates significant proficiency in managing the logistical and administrative burdens inherent in TTRPGs. Contemporary platforms successfully automate routine gameplay loops, including tracking experience points (XP), monitoring spell slots, handling short and long rest resource recovery, and automatically calculating attack, damage, and saving throws during combat encounters.5 Commercial implementations, such as the AI Dungeon platform and the Friends & Fables multiplayer system, have deployed specialized AI agents capable of handling 5th Edition (5e) combat, world-building, and non-player character (NPC) logic.3 These systems excel in their availability—they never cancel sessions, require zero prep time, and can instantaneously generate infinite side quests.3

However, evaluating LLMs purely on their administrative utility obscures deeper systemic limitations. Research utilizing the GTBench framework indicates that while LLMs excel in probabilistic, incomplete-information scenarios—such as poker or narrative bluffing—they experience catastrophic failures when tasked with strictly logical, rule-based reasoning, such as calculating complex critical hit modifiers or adhering to rigid spatial mechanics.3 D\&D lives precisely in the middle of this spectrum, featuring deterministic combat rules layered beneath probabilistic dice rolls and incomplete player knowledge.3 Consequently, a naive application of LLMs to TTRPGs often results in AI DMs generating highly compelling prose while simultaneously inventing non-existent magic items, ignoring established stat block limitations, or hallucinating damage outputs (e.g., declaring a standard fireball deals 427 damage).3

This dichotomy establishes D\&D and similar TTRPGs as ideal benchmarking environments for evaluating the long-term performance of autonomous agents. The ruleset requires multistep planning, continuous state tracking, and collaborative human-AI coordination over extended temporal horizons.1 Studies conducted at institutions such as the University of California San Diego have actively utilized D\&D to test models like Claude 3.5 Haiku, GPT-4, and DeepSeek-V3, finding that while some models demonstrate superior reliability in rule adherence, the overarching challenge of maintaining long-context dependency remains.1 Consequently, the development of an effective AI DM necessitates transitioning away from monolithic, single-prompt LLM architectures toward hybrid, multi-agent frameworks capable of separating creative narrative generation from strict mechanical adjudication.

## **Architectural Paradigms for Game Master AI**

The challenge of engineering an LLM to function as a DM lies in reconciling the fluid, open-ended nature of human imagination with the rigid state-machine requirements of a game engine. A singular approach—feeding turn-by-turn data into a single LLM context window—suffers from rapid degradation. Research indicates that as the context length grows, the accuracy of the LLM in maintaining game state drops below 65%, rendering it incapable of tracking cascading variables like resistances, evasion rolls, and counterspells.2 To mitigate this, advanced architectures deploy Multi-Agent Systems (MAS) coupled with Agentic Retrieval-Augmented Generation (RAG).

### **The "Narrator" and "Rules Lawyer" Dichotomy**

To effectively manage the dual requirements of a TTRPG, system architectures increasingly adopt a decoupled approach, conceptually mirroring the traditional tabletop dynamics of the "Narrator" and the "Rules Lawyer." In traditional human play, the Narrator role is focused on world-building, sensory description, and NPC dialogue, setting the scene and guiding the overarching story.7 Conversely, the "Rules Lawyer" is a term—often used pejoratively in human circles—for a participant who strictly enforces game mechanics, ensuring that actions align exactly with the physical and magical laws documented in the game manuals.8

In a multi-agent AI architecture, these roles are instantiated as specialized, interacting sub-systems. This prevents the primary narrative engine from becoming bogged down by computational tasks for which it is fundamentally unsuited. A deterministic rule-based agent acts as the Rules Lawyer, calculating discrete values, updating JSON-structured character sheets, and validating action legality based on predefined schemas.12 Simultaneously, an LLM-driven Narrator agent translates these mechanical state changes into fluid, natural language outputs. If the Narrator attempts to output a hallucinated state—such as granting a player a non-existent spell—the Rules Lawyer agent acts as an execution environment, rejecting the output and prompting the Narrator to generate a compliant response before the user ever sees the text.14

This separation of concerns is critical for deploying LLMs in safety-critical or logic-heavy environments. By offloading arithmetic and state tracking to symbolic engines or fine-tuned structured-output models, the LLM is freed to focus purely on semantic interpretation and thematic coherence. Frameworks such as Mastra provide a TypeScript-first design for building these multi-agent systems, where state machines orchestrate complex sequences of AI operations, ensuring that business logic supersedes unpredictable agent autonomy.16

| Architectural Component | Primary Function | Technical Implementation | Core Limitation Addressed |
| :---- | :---- | :---- | :---- |
| **Narrator Agent** | Contextual storytelling, sensory description, and NPC emotional dialogue. | Large Language Model (e.g., LLaMA-3, GPT-4) with high temperature and persona prompting. | Mitigates robotic or overly mechanical responses; fosters player immersion. |
| **Rules Lawyer Agent** | State tracking, mathematical calculation, and action validation. | Deterministic scripts, traditional APIs, or fine-tuned structured-output models. | Eliminates arithmetic hallucinations and prevents the fabrication of game mechanics. |
| **Context Manager** | Long-term memory retrieval and continuity enforcement. | Agentic RAG combined with vector databases and semantic search. | Prevents context window overflow and maintains narrative coherence over long sessions. |
| **Difficulty Assessor** | Real-time adjustment of encounter balancing. | Reinforcement Learning algorithms operating on contextual bandit frameworks. | Prevents static, predictable gameplay by adapting to dynamic player capabilities. |

### **Instruction Tuning vs. Reasoning Models in Mechanics**

The process of translating natural language player intent into rigid game mechanics is an area of active research. Experiments utilizing the FIREBALL dataset to map natural language to Avrae Discord bot commands for D\&D have yielded counterintuitive insights regarding model selection.17 When comparing a dedicated reasoning model (DeepSeek-R1-Distill-LLaMA-8B) against an instruction-tuned model (LLaMA-3.1-8B-Instruct), findings demonstrated that instruct models were fundamentally superior for strict mechanical formatting.17

Notably, forcing Chain-of-Thought (CoT) reasoning in smaller models actually degraded their performance on rigid translation tasks.18 This implies that the translation of player intent into mechanical action relies more heavily on precise instruction-following capabilities than on deep, multi-step logical deduction.18 Consequently, the "Rules Lawyer" agents within an RPG architecture do not require the massive parameter counts of generalized reasoning models; instead, they operate more efficiently as highly specialized Small Language Models (SLMs) fine-tuned on directed acyclic graph (DAG) synthetic datasets.19 This targeted approach allows for real-time generation with predictable latency suitable for local game engine constraints, bypassing the latency bottlenecks of cloud-dependent LLMs.19

### **Agentic Retrieval-Augmented Generation (RAG)**

Traditional RAG systems retrieve documents based on a fixed query in a single step, appending the retrieved context to the LLM prompt. While effective for static knowledge bases, this naive approach fails in the dynamic, evolving state of an RPG campaign where context is constantly shifting.21 For example, simply retrieving the rules for "grappling" does not inform the LLM of the specific environmental hazards present in the current scene or the target's current stamina.

Agentic RAG represents a substantial evolution, wherein specialized AI agents actively plan, reason, and adapt their retrieval strategies. These agents execute an iterative "reason, act, observe, repeat" loop.21 When a player attempts a complex maneuver, a Query Analysis Agent interprets the intent, queries a database for relevant rules, queries a separate state-tracker for the NPC's current conditions, and passes the synthesized data to a Generation Agent.22

Furthermore, embedding-free RAG architectures have been proposed, utilizing custom importance measures to guide searches via the LLM's native language understanding and logical reasoning, rather than delegating retrieval strictly to vector embedding distances.23 This approach iterates until a stop check condition is met, dramatically improving the contextual relevance of retrieved lore or mechanics.23 The application of such systems extends beyond gaming; analogous multi-agent RAG patterns are being deployed to manage complex heterogeneous data sources in industrial settings, proving the robustness of the architecture.24

## **Hallucination Management and the Mechanics of Creativity**

In the context of TTRPGs, the phenomenon of LLM hallucination requires a nuanced reevaluation. In strict data environments—such as the legal field, where LLMs have notoriously generated bogus judicial decisions and fake internal citations—hallucinations are fatal flaws.26 However, in creative storytelling, hallucination is virtually indistinguishable from imagination. Generative models extrapolating beyond their training data to invent novel narrative elements are performing the exact function required of a human Dungeon Master.27

The technical challenge lies in managing the boundary between beneficial narrative hallucination and destructive mechanical hallucination. Research suggests that creativity and factuality function as tunable dials, adjustable in real-time through specific activation directions and system prompts.28 To harness this, developers employ Game Knowledge Management Systems (G-KMS), which provide a structured pipeline transforming unstructured narrative inputs into engine-executable knowledge artifacts.14

G-KMS enforces schema-governed generation, integrating knowledge grounding, normalization-based repair, and engine-aligned knowledge admission.14 This ensures that while the LLM has complete freedom to invent the *lore* of a new sword, the *mechanics* of the sword adhere strictly to bounded accuracy guidelines and JSON formatting constraints.14 By treating hallucination not as a defect but as an expected behavior governed by operational guardrails, developers can unlock the creative potential of AI without sacrificing engine compatibility.14

## **Reinforcement Learning and Dynamic Encounter Balancing**

Balancing combat encounters to match the fluctuating capabilities of a player party is notoriously difficult, requiring a deep understanding of resource economy, party synergy, and tactical positioning.30 In classical video game design, inventory theory and dynamic systems are explicitly manipulated to manage the exchange of resources between the world and the player, ensuring the experience remains engaging rather than boring or frustrating.31 In automated RPG environments, static difficulty scaling rapidly leads to predictable gameplay. To address this, recent advancements have hybridized LLMs with Reinforcement Learning (RL) to create sophisticated Dynamic Difficulty Adjustment (DDA) engines.

### **The NTRL Framework**

The Encounter Generation via Reinforcement Learning (NTRL) framework exemplifies this approach. NTRL automates DDA by operating within a contextual bandit framework, utilizing real-time assessments of party attributes to dynamically select enemy compositions.30 The state space is mathematically augmented with a synergy vector, tracking the interactions between selected enemy classes to ensure coherent and challenging encounters.32 During inference, the NTRL agent generates combat scenarios that optimize enemy synergy and balance the experience economy instantly.33

Empirical evaluations of the NTRL framework demonstrated a 200% increase in combat longevity and a 16.67% decrease in post-combat player hit points, all while maintaining a consistent 70% win rate for the players.33 This indicates that the AI was able to significantly elevate the tactical challenge and resource depletion required to achieve victory, performing comparably to human DMs in assessing difficulty and promoting strategic gameplay.33

### **RKHS-RL and Output Entropy Optimization**

Addressing the curse of dimensionality in large or continuous state spaces, researchers have introduced non-parametric online RL algorithms such as RKHS-RL. By utilizing reproducing kernels, RKHS-RL can handle infinite state and action spaces alongside nonlinear transition probabilities.35 This mathematical rigor guarantees a sublinear regret bound, allowing the RL agent to optimally balance exploration and exploitation when designing encounters.35

Furthermore, researchers have deployed LLM-based prediction strategies to adjust difficulty in real-time. By measuring the output entropy of LLMs, systems can gauge the unpredictability or complexity of a scenario, adjusting the AI's aggressiveness, decision flexibility, or resource distribution to maintain the psychological concept of "flow".36 Sub-hypotheses in game-based interaction settings confirm that LLM-supported AI systems exhibit higher decision flexibility and lower response times than traditional machine learning algorithms when scaling difficulty dynamically.36

| DDA Metric | Static Balancing | RL/LLM Hybrid Balancing (e.g., NTRL) | Impact on Player Experience |
| :---- | :---- | :---- | :---- |
| **Encounter Generation** | Pre-scripted enemy tables. | Contextual bandit framework with synergy vectors. | Encounters feel tailored to current party state. |
| **Combat Longevity** | Baseline duration. | \+200% increase in encounter duration. | Promotes deeper tactical engagement and strategic depth. |
| **Resource Depletion** | Variable, often undertuned. | \-16.67% decrease in post-combat hit points. | Increases dramatic tension without causing unwinnable scenarios. |
| **Win Rate** | Highly variable based on DM skill. | Maintained at a stable 70%. | Ensures psychological "flow" by avoiding excessive frustration. |

## **Multimodal Procedural Content Generation (PCG)**

The scope of AI Dungeon Masters extends beyond text generation into the realm of Procedural Content Generation (PCG), enabling the real-time creation of spatial layouts, visual assets, and complex 3D environments. Traditional PCG algorithms—such as search-based methods or noise functions—have long been utilized to generate maps and art assets, reducing production costs and increasing replay value.38 However, they often struggle to maintain thematic cohesion and semantic logic across diverse domains.38 The integration of Multimodal LLMs fundamentally alters this paradigm, allowing systems to ingest both textual descriptions and visual sketches to synthesize coherent, interactive worlds.41

### **The LatticeWorld Framework**

A premier example of this advancement is the LatticeWorld framework, which pairs lightweight models (e.g., LLaMA-2-7B) with industry-grade rendering engines like Unreal Engine 5\.42 LatticeWorld decouples the generation process into three distinct phases: scene layout, environmental configuration, and procedural rendering.42

To overcome the spatial reasoning limitations of text-based LLMs, LatticeWorld employs a novel symbolic representation strategy. Visual inputs, such as height maps, are aligned to the LLM token space via a CLIP encoder and CNN projection.42 A scene layout image is mathematically compressed into a ![][image1] symbolic matrix (where ![][image2]), with each symbol corresponding to a specific type of asset.44 This matrix is then converted into a structured string format that the LLM can efficiently process and manipulate, allowing it to understand the distribution of scene assets.44

Once the LLM generates a cohesive symbolic layout based on narrative prompts, a secondary translation process maps these symbols into engine-native properties, spawning dynamic agents and physical objects within the 3D space.44 Evaluation of LatticeWorld demonstrated a 90-fold increase in industrial production efficiency while maintaining high creative quality and physically plausible multi-agent interactivity compared to traditional manual production methods.45

### **PCGRLLM and Hybrid Agent Pipelines**

Complementing spatial generation are hybrid models like PCGRLLM, which integrate LLMs with Reinforcement Learning for robust asset creation. PCGRLLM utilizes LLM-driven reward design to train PCGRL agents, leveraging sophisticated chain-of-thought, tree-of-thought, and graph-of-thought prompt engineering.41 This iterative feedback loop ensures that the generated content strictly adheres to functional playability constraints, achieving up to a 415% relative accuracy improvement over zero-shot baselines.41

Similarly, frameworks such as CrawLLM utilize specialized models (e.g., Mixtral 8x7B) to act as a scaffold for automated, theme-driven asset generation. In this pipeline, the LLM dictates the narrative rules, while interconnected modules (such as Stable Diffusion XL augmented with ControlNet) generate corresponding visual assets, ensuring that a generated dungeon maintains both narrative logic and visual consistency.40 Other frameworks, such as 3Dify, categorize themselves as human-in-the-loop and mixed-initiative design tools, utilizing the Model Context Protocol (MCP) and RAG to allow recurrent feedback and manual repair of generated 3D assets, balancing creative control with semantic precision.41

## **Traditional Mechanics Versus LLM-Native Fluid Systems**

The rigid, grid-based combat of classical D\&D 5e presents immense challenges for LLMs due to the reliance on spatial geometry, sequential turn orders, and cascading arithmetic. In traditional D\&D, executing a single attack involves checking movement range against a grid, rolling a d20 against an Armor Class, calculating disparate damage types from stat modifiers and magical properties, and evaluating conditional triggers.48 This highly deterministic sequence leaves little room for linguistic interpretation, often causing LLMs to lose context or invent rules when functioning as a standalone agent.2

Consequently, researchers and developers are increasingly exploring "LLM-native" game designs that leverage the inherent strengths of natural language processing.49 Narrative-first systems, such as those modeled after the Powered by the Apocalypse (PbtA) or Dungeon World frameworks, resolve actions using abstracted, fiction-first mechanics.48 In these systems, a player rolls dice (typically 2d6) to determine broad narrative outcomes—such as full success, success with a complication, or a miss—and the LLM interprets the result contextually to drive the story forward.50

For example, a multi-agent simulation operating on a Dungeon World framework demonstrated profound emergent storytelling. Autonomous agents driven by internal logic and motivations interacted within a dynamic geography.50 Because the resolution mechanics were narrative rather than strictly mathematical, the LLM seamlessly generated outcomes with trade-offs. In one instance, a druidic order accidentally destabilized their own power base while attempting to rewrite regional traditions from within; in another, an assassin cult spontaneously built a prison for extraplanar beings due to a thinning of reality.50 This fluid architecture proves significantly more resilient to model decay and state-tracking errors, as the game state is maintained through semantic consensus rather than brittle numerical matrices.

Furthermore, integrating custom, abstracted mechanics like Stress or Corruption trackers—similar to those found in the Free League Alien RPG or the Alexandrian Remix of Descent Into Avernus—allows the LLM to manage global effects on NPC interactions dynamically, rather than tracking discrete hit point values.52 The transition to LLM-native frameworks ensures that the game engine plays to the strengths of the neural network (semantic understanding, thematic extrapolation) rather than exposing its weaknesses (arithmetic computation, rigid spatial mapping).

## **Emotional Intelligence, Social-Emotional Learning, and Player Agency**

The role of a human Dungeon Master is profoundly social, requiring high levels of emotional intelligence (EI) to read the room, adjust tension, and provide a psychologically safe environment for players to explore complex themes.53 Tabletop role-playing games are widely recognized as potent tools for social-emotional learning (SEL). Through the "alibi of role-play," players can experience failure, interpersonal conflict, and moral dilemmas without risking their real-life identity.53 Studies from the University of Toronto and UC Berkeley suggest that storytelling and role-playing can demonstrably increase emotional intelligence, acting as "empathy workouts" that build social cognition.55

A human DM facilitates this by framing failures not as punishments, but as scaffolding for narrative development—such as allowing a failed skill check to reveal a new clue rather than halting progress.53 As AI systems assume this role, evaluating their capacity for emotional regulation and empathy becomes paramount.57 Current generation LLM agents exhibit measurable deficits in this area. While human players are highly sensitive to emotional vividness and shared experience, AI responses often lack the nuance required for deep empathic expression.57

LLM DMs struggle to appropriately calibrate tension. Quantitative evaluations using t-tests to compare human DMs and LLM agents reveal that while LLMs perform adequately in maintaining narrative flow and creative engagement, they fail to achieve statistical significance in generating necessary dramatic tension or effectively managing negative affect.59 To quantify and improve this deficiency, researchers have developed novel assessment methodologies, such as the PAGE (Perceiving AI Generated Emotions) metric, which utilizes generative AI to create standardized, customizable assessments of emotion perception.60

### **Measuring Player Agency**

The perception of player agency within narrative-focused games is complex, extending beyond the mere presence of meaningful choices to include social investment and genre expectations.61 Agency is contextually situated and distributed between the player and the system.63 When comparing iterations of interactive LLM narratives, systems that provide fluid, dynamic responses that accurately interpret player intentions foster a deeper sense of agency.64 Players utilizing advanced LLM-driven RPGs reported that the experience felt less like being constrained by "guard rails" and more akin to "guiding the game master," resulting in significantly deeper immersion compared to rigid, pre-scripted dialogue trees.64

However, the ethical deployment of AI DMs requires robust transparency. The integration of emotional algorithms raises concerns regarding algorithmic bias, cross-cultural emotion misinterpretation, and data privacy.58 Ensuring that AI systems do not perpetuate stereotypes or inadvertently penalize players for culturally specific role-playing decisions is critical for maintaining an inclusive gaming environment.66

## **Evaluation Frameworks and Benchmarking LLM Agency**

The proliferation of LLM-based agents has necessitated the development of rigorous, standardized benchmarks to evaluate their efficacy in complex, multi-step environments like TTRPGs. Because traditional natural language processing benchmarks fail to capture the interactive, long-horizon nature of game dynamics, novel evaluation frameworks have been constructed, becoming a focal point of major academic conferences like KDD 2025 and IJCAI 2025\.67 These tutorials emphasize the need to evaluate task success rates, tool utilization, robustness, and multi-agent coordination efficiency.69

### **RPGBench**

RPGBench serves as a foundational metric for assessing LLMs specifically as text-based RPG engines. It decomposes the evaluation into two primary vectors: Game Creation (GC) and Game Simulation (GS).70 To ensure that generated games are logically sound and playable, RPGBench employs an automated Breadth-First Search (BFS) Validity Checker, which formally verifies that game state transitions are reachable and mechanically consistent.70

The benchmark utilizes advanced LLMs acting as judges to score the generated content across multiple dimensions:

* **Action Quality:** Evaluated on diversity, relevance, and clarity.70  
* **Interestingness:** Assesses the narrative engagement of the output, normalized on a continuous scale from 0 to 1\.70  
* **Role-Playing Factual Consistency:** Verifies the generated narration against a strict, pre-defined list of facts pertaining to the NPCs and the world state.70

### **The Orak Benchmark**

Moving beyond text-based simulation, the Orak benchmark evaluates the capacity of agentic LLMs to interact with complex, visual game states across titles such as Super Mario, Pokémon, and StarCraft II.71 Developed by KRAFTON AI, Orak challenges agents to navigate unfamiliar environments, adhere to game-specific rules absent from common-sense pretraining, and achieve long-term goals through continuous interaction.74

The evaluation encompasses both text-only and multimodal vision-language agents connected via the Model Context Protocol (MCP).72 Scoring is highly structured, weighing performance across different game genres (e.g., Pokémon and StarCraft II hold a 30% weight, while 2048 holds 15%) to generate an aggregate metric of planning, adaptability, and tool-use efficiency.72 This benchmark fundamentally probes whether an LLM can graduate from conversational mimicry to executing reliable, strategic agency within a chaotic environment.75

### **Alympics and Strategic Rationality**

To specifically evaluate the game-theoretic and socioeconomic reasoning of LLM agents, platforms like Alympics simulate multiplayer scenarios, including the Prisoner's Dilemma, Trust Games, and resource auctions.77 Researchers utilizing these platforms have proposed the Strategic Rationality Score (SRS), a composite metric that normalizes deviations from optimal Nash equilibria across games, enabling the quantitative benchmarking of an LLM's rationality.79

Findings from these environments reveal significant vulnerabilities in current LLM architectures. Agents demonstrate inconsistent equilibrium-seeking behavior and minimal adaptation over repeated interactions, indicating profound limitations in opponent modeling and long-term strategic reasoning.79 In zero-sum games, such as Tic-Tac-Toe, performance variations are highly dependent on prompt structuring; models like GPT-4 required specific illustration prompts to minimize invalid moves and optimize victory paths, underscoring the brittleness of LLM spatial reasoning.80 Furthermore, performance in game-theoretic scenarios exhibits unexpected sensitivity to the language of interaction (e.g., testing across English, French, Arabic, Vietnamese, and Mandarin), highlighting latent cultural biases within the models' training data that skew rational decision-making.81

To address these deficits, researchers are exploring unsupervised training methodologies, such as regret-loss minimization. By studying the no-regret behaviors of LLMs in canonical non-stochastic online learning problems, developers can mathematically guarantee generalization bounds, forcing the attention models to converge toward optimal learning algorithms without requiring vast datasets of labeled actions.82

## **Research Plan: Advancing RPGBench, Orak, and Alympics**

To continue the trajectory established by current literature and overcome the identified gaps in autonomous agent modeling, our upcoming research plan is structured across three distinct phases. Each phase targets a specific evaluation framework—RPGBench, Orak, and Alympics—to holistically measure and improve LLM performance in interactive, rule-bound environments.

### **Phase 1: Deepening Textual and Mechanical Coherence via RPGBench**

The primary objective here is to advance the evaluation of LLMs acting strictly as text-based RPG engines, balancing imaginative prose with rigid, mechanically sound game states. RPGBench provides the foundational dichotomy of Game Creation (GC) and Game Simulation (GS).

* **Methodology:** We will generate a structured, playable event-state representation for RPG worlds and utilize the automated Breadth-First Search (BFS) Validity Checker to strictly enforce termination conditions and logical reachability.  
* **Evaluation Focus:** The research will pit state-of-the-art reasoning models against highly fine-tuned Small Language Models (SLMs) to assess performance across both objective (variable updates, adherence to game mechanics) and subjective measures. Subjective assessments—such as narrative interestingness, action quality, and role-playing consistency—will be conducted utilizing an advanced LLM-as-a-judge framework.  
* **Expected Outcomes:** By systematically fusing rule-based assessments with LLM-based judgments, we aim to map the exact threshold at which long-context scenarios cause LLMs to fail at verifiable game mechanics, thereby establishing a new baseline for immersive, controllable interactive storytelling.

### **Phase 2: Multimodal and Real-Time Agentic Execution via Orak**

Transitioning from purely textual environments to complex, visually dynamic simulations, the second phase will leverage the Orak benchmark. Orak is designed to train and evaluate LLM agents across 12 diverse, popular video games (including StarCraft II, Pokémon, and Super Mario).

* **Methodology:** We will deploy agents using the Model Context Protocol (MCP), which provides a standardized, plug-and-play interface enabling LLMs to interact directly with game environments without relying on bespoke, hard-coded connectors.  
* **Evaluation Focus:** Our experiments will replicate the conditions of the recent global Orak Challenge, tracking agent performance in planning, adaptability, and cross-genre generalization under strict time and resource limits.72 We will conduct a comparative study separating tracks for lightweight models (under 8 billion parameters) versus open, frontier models.72  
* **Expected Outcomes:** This phase will yield quantitative data on how well multi-modal agents handle partial observability and shifting UIs, validating the efficacy of fine-tuning datasets composed of expert LLM gameplay trajectories to adapt pre-trained LLMs into versatile gaming agents.

### **Phase 3: Strategic Rationality and Socioeconomic Modeling via Alympics**

The final phase will focus on the social, cooperative, and competitive capabilities of multi-agent networks using the Alympics framework. Alympics functions as an LLM agent-based game theory playground, comprising a Sandbox Playground and diverse Agent Players.78

* **Methodology:** Agents will be subjected to complex, multi-round scenarios, specifically focusing on the "Water Allocation Challenge" to test resource scarcity, survival strategy, and auction theory.  
* **Evaluation Focus:** The research will quantitatively and qualitatively analyze game determinants and agent strategies, measuring deviations from the Nash equilibrium.  
* **Expected Outcomes:** By comparing the outcomes of LLM simulations against predicted results from classical auction theory and conducting comprehensive human assessments, this phase will reveal the current limits of LLMs in emulating complex human strategic behaviors and decision-making in socioeconomic contexts.

## **Filling the Research Gaps: Future Trajectories in LLM RPG Design**

The synthesis of current research reveals several critical gaps in the deployment of LLMs within TTRPG environments, mapping direct trajectories for future engineering and narratological studies.

First, the dependency on cloud-based, monolithic LLMs introduces latency constraints incompatible with real-time multiplayer gaming. The latency required to generate a response, validate it through a separate rules agent, and output it to the user disrupts the psychological immersion of the players.19 Research is pivoting toward Small Language Models (SLMs) fine-tuned on highly specific, synthetic Directed Acyclic Graph (DAG) datasets.19 By deploying networks of specialized SLMs—each managing a discrete function such as rhetorical combat, local lore retrieval, or spatial reasoning—developers can achieve predictable, sub-second latency suitable for local game engine constraints.20

Second, the challenge of long-context dependency remains largely unsolved. While Agentic RAG mitigates context overflow, the synthesis of disparate historical facts into a cohesive, emotional narrative degrades over a campaign spanning months. Future architectures must integrate episodic memory networks capable of hierarchical summarization, wherein an LLM continuously compresses short-term conversational logs into abstracted semantic concepts, much like human memory consolidation.83 The development of standardized diagnostic tools for failure attribution in long-horizon interactions is urgently required to advance this field.69

Third, the development of emotional intelligence within AI DMs requires moving beyond rudimentary sentiment analysis. If LLMs are to manage the complex emotional scaffolding of a TTRPG, they require access to multimodal physiological data or advanced sentiment trajectory tracking. Developing models that can map verbal cadence, hesitation, and collaborative enthusiasm to dynamic adjustments in narrative pacing will be the next frontier in fostering genuine psychological safety and player agency.58

Finally, the philosophical alignment of game mechanics and LLM capabilities requires a paradigm shift. Rather than forcing probabilistic language models to adjudicate highly deterministic simulations like D\&D 5e, game designers must formulate "LLM-native" RPG systems.49 These systems will intrinsically utilize semantic interpretation, subjective difficulty scaling, and degrees of narrative success as their core resolution mechanics, fundamentally aligning the structure of the game with the architectural strengths of artificial neural networks.

## **Conclusion**

The pursuit of an artificial Dungeon Master is not merely an exercise in entertainment technology; it serves as a rigorous crucible for advancing artificial general intelligence. Tabletop role-playing games demand a synthesis of logical adherence, spatial reasoning, emotional intelligence, and unbounded creativity—a combination that aggressively stress-tests the boundaries of current Large Language Models.

The evidence confirms that single-model implementations are structurally insufficient for this task. The future of AI in RPGs relies on the deployment of sophisticated Multi-Agent Systems, decoupling the rigid enforcement of game state from the fluid generation of narrative prose. By integrating Agentic Retrieval-Augmented Generation, Reinforcement Learning for dynamic difficulty adjustment, and symbolic mapping for procedural 3D world generation, developers can construct robust execution environments that cage the hallucination of LLMs, transmuting it into directed, playable creativity.

As evaluation frameworks like RPGBench, Orak, and Alympics continue to refine the quantitative measurement of strategic reasoning, emotional intelligence, and player agency, the iterative development of AI DMs will yield profound insights. Ultimately, the engineering solutions pioneered to facilitate a seamless, emotionally resonant game of Dungeons & Dragons will lay the foundational architecture for reliable, emotionally intelligent, and autonomous AI agents deployed across broader socio-economic, educational, and industrial domains.

#### **Works cited**

1. From Chatbots to Dice Rolls: Researchers Use D\&D to Test AI's Long-term Decision-making Abilities \- UC San Diego Today, accessed February 25, 2026, [https://today.ucsd.edu/story/from-chatbots-to-dice-rolls-researchers-use-dd-to-test-ais-long-term-decision-making-abilities](https://today.ucsd.edu/story/from-chatbots-to-dice-rolls-researchers-use-dd-to-test-ais-long-term-decision-making-abilities)  
2. The D\&D Blueprint: How Role-Playing Engines Can Guide Next-Gen AI \- ShiftMag, accessed February 25, 2026, [https://shiftmag.dev/dungeons-dragons-dnd-ai-game-engine-6240/](https://shiftmag.dev/dungeons-dragons-dnd-ai-game-engine-6240/)  
3. LLMs as Dungeon Masters: Can AI Run a Tabletop Game Without ..., accessed February 25, 2026, [https://dev.to/pracode\_2503/llms-as-dungeon-masters-can-ai-run-a-tabletop-game-without-cheating-425m](https://dev.to/pracode_2503/llms-as-dungeon-masters-can-ai-run-a-tabletop-game-without-cheating-425m)  
4. Reinforcement Learning Environment with LLM-Controlled Adversary in D\&D 5th Edition Combat \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2503.15726v1](https://arxiv.org/html/2503.15726v1)  
5. The current state of AI Dungeon Masters : r/dndnext \- Reddit, accessed February 25, 2026, [https://www.reddit.com/r/dndnext/comments/1dyhc69/the\_current\_state\_of\_ai\_dungeon\_masters/](https://www.reddit.com/r/dndnext/comments/1dyhc69/the_current_state_of_ai_dungeon_masters/)  
6. PSA: AI is not a reliable rules reference for RPGs : r/DnDcirclejerk \- Reddit, accessed February 25, 2026, [https://www.reddit.com/r/DnDcirclejerk/comments/1r8h9lz/psa\_ai\_is\_not\_a\_reliable\_rules\_reference\_for\_rpgs/](https://www.reddit.com/r/DnDcirclejerk/comments/1r8h9lz/psa_ai_is_not_a_reliable_rules_reference_for_rpgs/)  
7. Handbook of Role-Playing Game Studies \- Scribd, accessed February 25, 2026, [https://www.scribd.com/document/822956369/The-Routledge-Handbook-of-Role-Playing-Game-Studiese](https://www.scribd.com/document/822956369/The-Routledge-Handbook-of-Role-Playing-Game-Studiese)  
8. Gamemastering \- Katrina Ostrander, accessed February 25, 2026, [https://katrinaostrander.com/wp-content/uploads/2025/03/Gamemastering-by-Brian-Jamison.pdf](https://katrinaostrander.com/wp-content/uploads/2025/03/Gamemastering-by-Brian-Jamison.pdf)  
9. Dungeon Master's Guide®, accessed February 25, 2026, [https://hellequin.net/oldRoot/Dungeon%20Master's%20Guide.pdf](https://hellequin.net/oldRoot/Dungeon%20Master's%20Guide.pdf)  
10. ISSUE 16 2025, accessed February 25, 2026, [https://journals.uu.se/IJRP/article/download/993/900/3479](https://journals.uu.se/IJRP/article/download/993/900/3479)  
11. RPG Terminology | PDF | Role Playing Games | Dungeons & Dragons \- Scribd, accessed February 25, 2026, [https://www.scribd.com/document/900529832/RPG-Terminology](https://www.scribd.com/document/900529832/RPG-Terminology)  
12. Large Language Models and Dynamic Difficulty Adjustment: An Integration Perspective, accessed February 25, 2026, [https://sol.sbc.org.br/index.php/sbgames\_estendido/article/download/32000/31802](https://sol.sbc.org.br/index.php/sbgames_estendido/article/download/32000/31802)  
13. Hybrid AI and LLM-Enabled Agent-Based Real-Time Decision Support Architecture for Industrial Batch Processes: A Clean-in-Place Case Study \- MDPI, accessed February 25, 2026, [https://www.mdpi.com/2673-2688/7/2/51](https://www.mdpi.com/2673-2688/7/2/51)  
14. Game Knowledge Management System: Schema-Governed LLM ..., accessed February 25, 2026, [https://www.mdpi.com/2079-8954/14/2/175](https://www.mdpi.com/2079-8954/14/2/175)  
15. awesome-lowcode/今日阅读.md at master \- GitHub, accessed February 25, 2026, [https://github.com/taowen/awesome-lowcode/blob/master/%E4%BB%8A%E6%97%A5%E9%98%85%E8%AF%BB.md](https://github.com/taowen/awesome-lowcode/blob/master/%E4%BB%8A%E6%97%A5%E9%98%85%E8%AF%BB.md)  
16. Architectures for Multi-Agent Systems \- Galileo AI, accessed February 25, 2026, [https://galileo.ai/blog/architectures-for-multi-agent-systems](https://galileo.ai/blog/architectures-for-multi-agent-systems)  
17. \[2510.18112\] Does Reasoning Help LLM Agents Play Dungeons and Dragons? A Prompt Engineering Experiment \- arXiv.org, accessed February 25, 2026, [https://arxiv.org/abs/2510.18112](https://arxiv.org/abs/2510.18112)  
18. Does Reasoning Help LLM Agents Play Dungeons and Dragons? A Prompt Engineering Experiment \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2510.18112v1](https://arxiv.org/html/2510.18112v1)  
19. 2601.23206v1 | PDF \- Scribd, accessed February 25, 2026, [https://www.scribd.com/document/991248180/2601-23206v1](https://www.scribd.com/document/991248180/2601-23206v1)  
20. High-quality generation of dynamic game content via small language models: A proof of concept \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2601.23206v1](https://arxiv.org/html/2601.23206v1)  
21. What is Agentic RAG? A Practical Guide for Data Teams \- Domo, accessed February 25, 2026, [https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams](https://www.domo.com/blog/what-is-agentic-rag-a-practical-guide-for-data-teams)  
22. Agentic RAG: Architecture, Use Cases, and Limitations \- Vellum AI, accessed February 25, 2026, [https://www.vellum.ai/blog/agentic-rag](https://www.vellum.ai/blog/agentic-rag)  
23. Beyond Vector Databases: RAG Architectures Without Embeddings \- DigitalOcean, accessed February 25, 2026, [https://www.digitalocean.com/community/tutorials/beyond-vector-databases-rag-without-embeddings](https://www.digitalocean.com/community/tutorials/beyond-vector-databases-rag-without-embeddings)  
24. LLM-based RecSys: Multi-agent Architectures\\\\ and Advanced RAG Techniques, accessed February 25, 2026, [https://thesis.unipd.it/retrieve/ecc36f73-ac30-440c-8e89-6df0408d050c/Russo\_Christian\_Francesco.pdf](https://thesis.unipd.it/retrieve/ecc36f73-ac30-440c-8e89-6df0408d050c/Russo_Christian_Francesco.pdf)  
25. A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data Sources \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2412.05838v1](https://arxiv.org/html/2412.05838v1)  
26. Hallucinating Law: Legal Mistakes with Large Language Models are Pervasive, accessed February 25, 2026, [https://hai.stanford.edu/news/hallucinating-law-legal-mistakes-large-language-models-are-pervasive](https://hai.stanford.edu/news/hallucinating-law-legal-mistakes-large-language-models-are-pervasive)  
27. Hallucinations in LLMs: Technical challenges, systemic risks and AI governance implications | IAPP, accessed February 25, 2026, [https://iapp.org/news/a/hallucinations-in-llms-technical-challenges-systemic-risks-and-ai-governance-implications](https://iapp.org/news/a/hallucinations-in-llms-technical-challenges-systemic-risks-and-ai-governance-implications)  
28. LLM hallucinations aren't bugs: The real challenges are confidence and context \- SignalFire, accessed February 25, 2026, [https://www.signalfire.com/blog/llm-hallucinations-arent-bugs](https://www.signalfire.com/blog/llm-hallucinations-arent-bugs)  
29. A Survey on Large Language Model Hallucination via a Creativity Perspective \- arXiv.org, accessed February 25, 2026, [https://arxiv.org/html/2402.06647v1](https://arxiv.org/html/2402.06647v1)  
30. \[2506.19530\] NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons \- arXiv, accessed February 25, 2026, [https://arxiv.org/abs/2506.19530](https://arxiv.org/abs/2506.19530)  
31. AI for Dynamic Difficulty Adjustment in Games \- Northwestern Computer Science, accessed February 25, 2026, [https://users.cs.northwestern.edu/\~hunicke/pubs/Hamlet.pdf](https://users.cs.northwestern.edu/~hunicke/pubs/Hamlet.pdf)  
32. (PDF) NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/392980109\_NTRL\_Encounter\_Generation\_via\_Reinforcement\_Learning\_for\_Dynamic\_Difficulty\_Adjustment\_in\_Dungeons\_and\_Dragons](https://www.researchgate.net/publication/392980109_NTRL_Encounter_Generation_via_Reinforcement_Learning_for_Dynamic_Difficulty_Adjustment_in_Dungeons_and_Dragons)  
33. NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons \- arXiv.org, accessed February 25, 2026, [https://arxiv.org/html/2506.19530v2](https://arxiv.org/html/2506.19530v2)  
34. NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2506.19530v1](https://arxiv.org/html/2506.19530v1)  
35. Exploring the State and Action Space in Reinforcement Learning with Infinite-Dimensional Confidence Balls | OpenReview, accessed February 25, 2026, [https://openreview.net/forum?id=U0c2IaQhHk](https://openreview.net/forum?id=U0c2IaQhHk)  
36. (PDF) Designing a Large Language Model-Based AI System for Dynamic Difficulty Adjustment in Digital Games \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/392409319\_Designing\_a\_Large\_Language\_Model-Based\_AI\_System\_for\_Dynamic\_Difficulty\_Adjustment\_in\_Digital\_Games](https://www.researchgate.net/publication/392409319_Designing_a_Large_Language_Model-Based_AI_System_for_Dynamic_Difficulty_Adjustment_in_Digital_Games)  
37. AI-Enhanced NPC Behavior and Game Balancing \- Geeta University, accessed February 25, 2026, [https://geetauniversity.edu.in/blog/game-balancing-ai-npc-behavior/](https://geetauniversity.edu.in/blog/game-balancing-ai-npc-behavior/)  
38. Procedural Content Generation in Games: A Survey with Insights on Emerging LLM Integration \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2410.15644v1](https://arxiv.org/html/2410.15644v1)  
39. Procedural Content Generation in Games: A Survey with Insights on Emerging LLM Integration \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/385888613\_Procedural\_Content\_Generation\_in\_Games\_A\_Survey\_with\_Insights\_on\_Emerging\_LLM\_Integration](https://www.researchgate.net/publication/385888613_Procedural_Content_Generation_in_Games_A_Survey_with_Insights_on_Emerging_LLM_Integration)  
40. Research: Procedural Content Generation \- Antonios Liapis, accessed February 25, 2026, [https://antoniosliapis.com/research/research\_pcg.php](https://antoniosliapis.com/research/research_pcg.php)  
41. Procedural Content Generation with LLMs \- Emergent Mind, accessed February 25, 2026, [https://www.emergentmind.com/topics/procedural-content-generation-with-llms](https://www.emergentmind.com/topics/procedural-content-generation-with-llms)  
42. LatticeWorld: LLM-Powered 3D World Generation \- YouTube, accessed February 25, 2026, [https://www.youtube.com/watch?v=\_t7oFjYf6O8](https://www.youtube.com/watch?v=_t7oFjYf6O8)  
43. \[2509.05263\] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation \- arXiv, accessed February 25, 2026, [https://arxiv.org/abs/2509.05263](https://arxiv.org/abs/2509.05263)  
44. LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2509.05263v1](https://arxiv.org/html/2509.05263v1)  
45. \[Quick Review\] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for\\n Interactive Complex World Generation \- Liner, accessed February 25, 2026, [https://liner.com/review/latticeworld-multimodal-large-language-modelempowered-framework-for-interactive-complex-world](https://liner.com/review/latticeworld-multimodal-large-language-modelempowered-framework-for-interactive-complex-world)  
46. LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/395339104\_LatticeWorld\_A\_Multimodal\_Large\_Language\_Model-Empowered\_Framework\_for\_Interactive\_Complex\_World\_Generation](https://www.researchgate.net/publication/395339104_LatticeWorld_A_Multimodal_Large_Language_Model-Empowered_Framework_for_Interactive_Complex_World_Generation)  
47. LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation \- ChatPaper, accessed February 25, 2026, [https://chatpaper.com/paper/186288](https://chatpaper.com/paper/186288)  
48. What's the difference between classical DnD system and narative system ? : r/AskGameMasters \- Reddit, accessed February 25, 2026, [https://www.reddit.com/r/AskGameMasters/comments/1enevyh/whats\_the\_difference\_between\_classical\_dnd\_system/](https://www.reddit.com/r/AskGameMasters/comments/1enevyh/whats_the_difference_between_classical_dnd_system/)  
49. AdaCoder: An Adaptive Planning and Multi-Agent Framework for Function-Level Code Generation \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/398643859\_AdaCoder\_An\_Adaptive\_Planning\_and\_Multi-Agent\_Framework\_for\_Function-Level\_Code\_Generation](https://www.researchgate.net/publication/398643859_AdaCoder_An_Adaptive_Planning_and_Multi-Agent_Framework_for_Function-Level_Code_Generation)  
50. I'm Running a Multi-Agent TTRPG Simulation with LLMs—and It's Creating New IP and Storylines I've Never Seen Before : r/rpg \- Reddit, accessed February 25, 2026, [https://www.reddit.com/r/rpg/comments/1kb6gwx/im\_running\_a\_multiagent\_ttrpg\_simulation\_with/](https://www.reddit.com/r/rpg/comments/1kb6gwx/im_running_a_multiagent_ttrpg_simulation_with/)  
51. OT121: Openumbra Thread \- Slate Star Codex, accessed February 25, 2026, [https://slatestarcodex.com/2019/02/11/ot121-openumbra-thread/](https://slatestarcodex.com/2019/02/11/ot121-openumbra-thread/)  
52. Thought of the Day: GenAI and RPGs \- The Alexandrian, accessed February 25, 2026, [https://thealexandrian.net/wordpress/53232/roleplaying-games/thought-of-the-day-genai-and-rpgs](https://thealexandrian.net/wordpress/53232/roleplaying-games/thought-of-the-day-genai-and-rpgs)  
53. What Would Your Character Do? Emotional Intelligence, Psychological Safety and Identity in TTRPG Design \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/399374453\_What\_Would\_Your\_Character\_Do\_Emotional\_Intelligence\_Psychological\_Safety\_and\_Identity\_in\_TTRPG\_Design](https://www.researchgate.net/publication/399374453_What_Would_Your_Character_Do_Emotional_Intelligence_Psychological_Safety_and_Identity_in_TTRPG_Design)  
54. Emotional Intelligence Trends 2025: The Future of EQ \- Equanima, accessed February 25, 2026, [https://equanima.io/emotional-intelligence-trends-2025/](https://equanima.io/emotional-intelligence-trends-2025/)  
55. Building Empathy at the Table: RPGs as a Tool for Social-Emotional Lea \- Nerd Sweat, accessed February 25, 2026, [https://nerdsweat.biz/blogs/playing-d-d/building-empathy-at-the-table-rpgs-as-a-tool-for-social-emotional-learning](https://nerdsweat.biz/blogs/playing-d-d/building-empathy-at-the-table-rpgs-as-a-tool-for-social-emotional-learning)  
56. How Tabletop RPGs Heal Hearts And Build Better People \- RPG Elite, accessed February 25, 2026, [https://rpgelite.us/how-tabletop-rpgs-heal-hearts-and-build-better-people/](https://rpgelite.us/how-tabletop-rpgs-heal-hearts-and-build-better-people/)  
57. Talk, Listen, Connect: How Humans and AI Evaluate Empathy in Responses to Emotionally Charged Narratives \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2409.15550v3](https://arxiv.org/html/2409.15550v3)  
58. (PDF) Systematic Review on AI in Emotional Intelligence and Psychological Education, accessed February 25, 2026, [https://www.researchgate.net/publication/391399126\_Systematic\_Review\_on\_AI\_in\_Emotional\_Intelligence\_and\_Psychological\_Education](https://www.researchgate.net/publication/391399126_Systematic_Review_on_AI_in_Emotional_Intelligence_and_Psychological_Education)  
59. Exploring the Potential of LLM-based Agents as Dungeon Masters in Tabletop Role-playing Games, accessed February 25, 2026, [https://studenttheses.uu.nl/bitstream/handle/20.500.12932/47209/Thesis\_Final.pdf](https://studenttheses.uu.nl/bitstream/handle/20.500.12932/47209/Thesis_Final.pdf)  
60. Measuring Emotion Perception Ability Using AI-Generated Stimuli: Development and Validation of the PAGE Test \- MDPI, accessed February 25, 2026, [https://www.mdpi.com/2079-3200/13/9/116](https://www.mdpi.com/2079-3200/13/9/116)  
61. Naked and on Fire”: Examining Player Agency Experiences in Narrative-Focused Gameplay | Semantic Scholar, accessed February 25, 2026, [https://www.semanticscholar.org/paper/fc2b6060fe98d06f6329c6dcbfc18edeef46d5cb](https://www.semanticscholar.org/paper/fc2b6060fe98d06f6329c6dcbfc18edeef46d5cb)  
62. Naked and on Fire”: Examining Player Agency Experiences in Narrative-Focused Gameplay | Request PDF \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/351422204\_Naked\_and\_on\_Fire\_Examining\_Player\_Agency\_Experiences\_in\_Narrative-Focused\_Gameplay](https://www.researchgate.net/publication/351422204_Naked_and_on_Fire_Examining_Player_Agency_Experiences_in_Narrative-Focused_Gameplay)  
63. Dimensions of Agency for Interactive Narrative Design \- Association for the Advancement of Artificial Intelligence (AAAI), accessed February 25, 2026, [https://cdn.aaai.org/Symposia/Spring/2009/SS-09-06/SS09-06-008.pdf](https://cdn.aaai.org/Symposia/Spring/2009/SS-09-06/SS09-06-008.pdf)  
64. Static Vs. Agentic Game Master AI for Facilitating Solo Role-Playing Experiences \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2502.19519v1](https://arxiv.org/html/2502.19519v1)  
65. The Effect of Context-aware LLM-based NPC Conversations on Player Engagement in Role-playing Video Games, accessed February 25, 2026, [https://projekter.aau.dk/projekter/files/536738243/The\_Effect\_of\_Context\_aware\_LLM\_based\_NPC\_Dialogues\_on\_Player\_Engagement\_in\_Role\_playing\_Video\_Games.pdf](https://projekter.aau.dk/projekter/files/536738243/The_Effect_of_Context_aware_LLM_based_NPC_Dialogues_on_Player_Engagement_in_Role_playing_Video_Games.pdf)  
66. AI Dungeon Masters: Dynamic Storytelling in Tabletop Roleplaying Games In 2024, accessed February 25, 2026, [https://blog.dealon.ai/ai-dungeon-masters-tabletop-roleplaying-games/](https://blog.dealon.ai/ai-dungeon-masters-tabletop-roleplaying-games/)  
67. Evaluating LLM-based Agents: Foundations, Best Practices and Open Challenges, accessed February 25, 2026, [https://research.ibm.com/publications/evaluating-llm-based-agents-foundations-best-practices-and-open-challenges](https://research.ibm.com/publications/evaluating-llm-based-agents-foundations-best-practices-and-open-challenges)  
68. KDD 2025 Tutorial: Evaluation & Benchmarking of LLM Agents, accessed February 25, 2026, [https://sap-samples.github.io/llm-agents-eval-tutorial/](https://sap-samples.github.io/llm-agents-eval-tutorial/)  
69. Evaluating LLM-based Agents: Metrics, Benchmarks, and Best Practices, accessed February 25, 2026, [https://samiranama.com/posts/Evaluating-LLM-based-Agents-Metrics,-Benchmarks,-and-Best-Practices/](https://samiranama.com/posts/Evaluating-LLM-based-Agents-Metrics,-Benchmarks,-and-Best-Practices/)  
70. RPGBench: Evaluating Large Language Models as Role-Playing Game Engines \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2502.00595v1](https://arxiv.org/html/2502.00595v1)  
71. Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2506.03610v2](https://arxiv.org/html/2506.03610v2)  
72. AIcrowd | Orak Game Agent Challenge 2025, accessed February 25, 2026, [https://www.aicrowd.com/challenges/orak-game-agent-challenge-2025](https://www.aicrowd.com/challenges/orak-game-agent-challenge-2025)  
73. krafton-ai/Orak \- GitHub, accessed February 25, 2026, [https://github.com/krafton-ai/Orak](https://github.com/krafton-ai/Orak)  
74. Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games | OpenReview, accessed February 25, 2026, [https://openreview.net/forum?id=H1ncX6O6Yh](https://openreview.net/forum?id=H1ncX6O6Yh)  
75. Finding an LLM That's Truly Good at Gaming\! The Birth of the 'Orak' Benchmark, accessed February 25, 2026, [https://www.krafton.ai/en/behind-story/6990/](https://www.krafton.ai/en/behind-story/6990/)  
76. (PDF) Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/392405979\_Orak\_A\_Foundational\_Benchmark\_for\_Training\_and\_Evaluating\_LLM\_Agents\_on\_Diverse\_Video\_Games](https://www.researchgate.net/publication/392405979_Orak_A_Foundational_Benchmark_for_Training_and_Evaluating_LLM_Agents_on_Diverse_Video_Games)  
77. LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts \- arXiv, accessed February 25, 2026, [https://arxiv.org/html/2509.16610v1](https://arxiv.org/html/2509.16610v1)  
78. ALYMPICS: LLM Agents Meet Game Theory \- ACL Anthology, accessed February 25, 2026, [https://aclanthology.org/2025.coling-main.193.pdf](https://aclanthology.org/2025.coling-main.193.pdf)  
79. Strategic Insights: Evaluating Large Language Models' Decision-Making in Multi-Player Game-Theoretic Environments \- ResearchGate, accessed February 25, 2026, [https://www.researchgate.net/publication/395478345\_Strategic\_Insights\_Evaluating\_Large\_Language\_Models'\_Decision-Making\_in\_Multi-Player\_Game-Theoretic\_Environments](https://www.researchgate.net/publication/395478345_Strategic_Insights_Evaluating_Large_Language_Models'_Decision-Making_in_Multi-Player_Game-Theoretic_Environments)  
80. Benchmarking Large Language Model (LLM) Performance for Game Playing via Tic-Tac-Toe \- MDPI, accessed February 25, 2026, [https://www.mdpi.com/2079-9292/13/8/1532](https://www.mdpi.com/2079-9292/13/8/1532)  
81. Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity? \- Frontiers, accessed February 25, 2026, [https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1703586/full](https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1703586/full)  
82. Do LLM Agents Have Regret? A Case Study in Online Learning and Games | OpenReview, accessed February 25, 2026, [https://openreview.net/forum?id=qn9tBYQHGi](https://openreview.net/forum?id=qn9tBYQHGi)  
83. Interactive Fiction with LLM Agents \- Emergent Mind, accessed February 25, 2026, [https://www.emergentmind.com/topics/interactive-fiction-games-with-llm-agents](https://www.emergentmind.com/topics/interactive-fiction-games-with-llm-agents)  
84. Dialogs with GenAI NPCs: Exploring Player Interactions with Speech Agents in a VR Game, accessed February 25, 2026, [https://www.tandfonline.com/doi/full/10.1080/10447318.2026.2620647](https://www.tandfonline.com/doi/full/10.1080/10447318.2026.2620647)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACsAAAAZCAYAAACo79dmAAAAnUlEQVR4Xu3RjQqFMAgF4L3/SxdFC9Gjx41+iPzgUp3pnavWSimlfMFy/DzR2hS5Yb+/YpOR/0jN4C2gLKLrR3vlVTozfRIJZYx38Ag7oMnQBijLmO3boD6ToQ1QxrC3xKAek5mgjQ87Uot4+5lMB/qZieqjNQkNq593vRA1MKyerXd6BtgHw4e5w2mpopulhg1f+QP0Z39rjlL+bQW/pFqmfhd2qQAAAABJRU5ErkJggg==>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADcAAAAZCAYAAACVfbYAAAAAoklEQVR4Xu2R0Q6FIAxD+f+f1micIV034QUI9iR7WFdMe28pQgjxAw6YiFbfMmBQFh53g2lLgcGzclgG9+VhRZhmuqM2Rg9n0ZPF+aIyTEPqt63TQ88b57XFHQJtBi0/THpnR6bNIsuS3W6YgWmzyLJE+gszZB80zNMzGZGPaRdMc6AJ91GwEl+FcRyfhoFgFpYJb5HPCzuxbbnw7xRCCPFwAqGoj3HOshk5AAAAAElFTkSuQmCC>